{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"encoded_cleaned_train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>...</th>\n",
       "      <th>hhs_geo_region_fpwskwrf</th>\n",
       "      <th>hhs_geo_region_kbazzjca</th>\n",
       "      <th>hhs_geo_region_lrircsnp</th>\n",
       "      <th>hhs_geo_region_lzgpxyit</th>\n",
       "      <th>hhs_geo_region_mlyzmhmf</th>\n",
       "      <th>hhs_geo_region_oxchjgsf</th>\n",
       "      <th>hhs_geo_region_qufhixun</th>\n",
       "      <th>census_msa_MSA, Not Principle  City</th>\n",
       "      <th>census_msa_MSA, Principle City</th>\n",
       "      <th>census_msa_Non-MSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   respondent_id  h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "0              0           1.0             0.0                        0.0   \n",
       "1              1           3.0             2.0                        0.0   \n",
       "2              2           1.0             1.0                        0.0   \n",
       "3              3           1.0             1.0                        0.0   \n",
       "4              4           2.0             1.0                        0.0   \n",
       "\n",
       "   behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "0                   0.0                   0.0                    0.0   \n",
       "1                   1.0                   0.0                    1.0   \n",
       "2                   1.0                   0.0                    0.0   \n",
       "3                   1.0                   0.0                    1.0   \n",
       "4                   1.0                   0.0                    1.0   \n",
       "\n",
       "   behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "0                          0.0                      1.0   \n",
       "1                          0.0                      1.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          1.0                      0.0   \n",
       "4                          1.0                      0.0   \n",
       "\n",
       "   behavioral_touch_face  ...  hhs_geo_region_fpwskwrf  \\\n",
       "0                    1.0  ...                      0.0   \n",
       "1                    1.0  ...                      0.0   \n",
       "2                    0.0  ...                      0.0   \n",
       "3                    0.0  ...                      0.0   \n",
       "4                    1.0  ...                      0.0   \n",
       "\n",
       "   hhs_geo_region_kbazzjca  hhs_geo_region_lrircsnp  hhs_geo_region_lzgpxyit  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      0.0                      1.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   hhs_geo_region_mlyzmhmf  hhs_geo_region_oxchjgsf  hhs_geo_region_qufhixun  \\\n",
       "0                      0.0                      1.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      1.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      1.0   \n",
       "\n",
       "   census_msa_MSA, Not Principle  City  census_msa_MSA, Principle City  \\\n",
       "0                                  0.0                             0.0   \n",
       "1                                  1.0                             0.0   \n",
       "2                                  1.0                             0.0   \n",
       "3                                  0.0                             1.0   \n",
       "4                                  1.0                             0.0   \n",
       "\n",
       "   census_msa_Non-MSA  \n",
       "0                 1.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train_h1n1 \\\n",
    ", y_test_h1n1, y_train_seasonal, y_test_seasonal \\\n",
    "      = train_test_split(df.drop(['h1n1_vaccine','seasonal_vaccine'], axis = 1)\n",
    "                                , df['h1n1_vaccine'], df['seasonal_vaccine']\n",
    "                                , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "\n",
    "X_train.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_train.columns.values]\n",
    "X_test.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_train.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(algorithms, target1, target2, features):\n",
    "    \n",
    "    for algorithm in algorithms:\n",
    "        print(f\"--- Evaluating {algorithm.__class__.__name__} ---\")\n",
    "        \n",
    "        # Create the pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('model', algorithm)\n",
    "        ])\n",
    "\n",
    "        # Fit the model and make predictions for target1\n",
    "        pipeline.fit(X_train, y_train_h1n1)\n",
    "        predictions1 = pipeline.predict(X_test)\n",
    "\n",
    "        # Print classification report for target1\n",
    "        print(f\"--- Classification Report for Target1 ({algorithm.__class__.__name__}) ---\")\n",
    "        print(accuracy_score(y_test_h1n1, predictions1))\n",
    "        print(confusion_matrix(y_test_h1n1, predictions1))\n",
    "\n",
    "        # Fit the model and make predictions for target2\n",
    "        pipeline.fit(X_train, y_train_seasonal)\n",
    "        predictions2 = pipeline.predict(X_test)\n",
    "\n",
    "        # Print classification report for target2\n",
    "        print(f\"--- Classification Report for Target2 ({algorithm.__class__.__name__}) ---\")\n",
    "        print(accuracy_score(y_test_seasonal, predictions2))\n",
    "        print(confusion_matrix(y_test_seasonal, predictions2))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating LogisticRegression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classification Report for Target1 (LogisticRegression) ---\n",
      "0.8238487457880943\n",
      "[[4009  203]\n",
      " [ 738  392]]\n",
      "--- Classification Report for Target2 (LogisticRegression) ---\n",
      "0.7203294646199925\n",
      "[[2162  729]\n",
      " [ 765 1686]]\n",
      "\n",
      "\n",
      "--- Evaluating RandomForestClassifier ---\n",
      "--- Classification Report for Target1 (RandomForestClassifier) ---\n",
      "0.8358292774241857\n",
      "[[4047  165]\n",
      " [ 712  418]]\n",
      "--- Classification Report for Target2 (RandomForestClassifier) ---\n",
      "0.7761138150505429\n",
      "[[2338  553]\n",
      " [ 643 1808]]\n",
      "\n",
      "\n",
      "--- Evaluating SVC ---\n",
      "--- Classification Report for Target1 (SVC) ---\n",
      "0.7884687383002621\n",
      "[[4212    0]\n",
      " [1130    0]]\n",
      "--- Classification Report for Target2 (SVC) ---\n",
      "0.541183077499064\n",
      "[[2891    0]\n",
      " [2451    0]]\n",
      "\n",
      "\n",
      "--- Evaluating KNeighborsClassifier ---\n",
      "--- Classification Report for Target1 (KNeighborsClassifier) ---\n",
      "0.7590789966304755\n",
      "[[3951  261]\n",
      " [1026  104]]\n",
      "--- Classification Report for Target2 (KNeighborsClassifier) ---\n",
      "0.5471733433171097\n",
      "[[1689 1202]\n",
      " [1217 1234]]\n",
      "\n",
      "\n",
      "--- Evaluating DecisionTreeClassifier ---\n",
      "--- Classification Report for Target1 (DecisionTreeClassifier) ---\n",
      "0.7529015350056159\n",
      "[[3538  674]\n",
      " [ 646  484]]\n",
      "--- Classification Report for Target2 (DecisionTreeClassifier) ---\n",
      "0.6748408835642081\n",
      "[[2007  884]\n",
      " [ 853 1598]]\n",
      "\n",
      "\n",
      "--- Evaluating GaussianNB ---\n",
      "--- Classification Report for Target1 (GaussianNB) ---\n",
      "0.7961437663796331\n",
      "[[3592  620]\n",
      " [ 469  661]]\n",
      "--- Classification Report for Target2 (GaussianNB) ---\n",
      "0.7470984649943841\n",
      "[[2095  796]\n",
      " [ 555 1896]]\n",
      "\n",
      "\n",
      "--- Evaluating GradientBoostingClassifier ---\n",
      "--- Classification Report for Target1 (GradientBoostingClassifier) ---\n",
      "0.8399475851740921\n",
      "[[3999  213]\n",
      " [ 642  488]]\n",
      "--- Classification Report for Target2 (GradientBoostingClassifier) ---\n",
      "0.7845376263571696\n",
      "[[2336  555]\n",
      " [ 596 1855]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the algorithms to evaluate\n",
    "algorithms = [LogisticRegression(), RandomForestClassifier(), SVC()\n",
    "              ,KNeighborsClassifier(),DecisionTreeClassifier()\n",
    "              ,GaussianNB(), GradientBoostingClassifier()]\n",
    "\n",
    "# Call the function to evaluate the models\n",
    "evaluate_models(algorithms, y_train_h1n1, y_train_seasonal, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
